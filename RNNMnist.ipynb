{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, TimeDistributed, Flatten, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 785) (2000, 785) (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('/root/sharedfolder/train.csv', delimiter=',')\n",
    "train, test = data[:40000, ...].astype(int), data[40000:, ...].astype(int)\n",
    "\n",
    "validate = np.genfromtxt('/root/sharedfolder/test.csv', delimiter=',').astype(int)\n",
    "\n",
    "print(train.shape, test.shape, validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (40000, 784)\n",
      "Train labels:   (40000,)\n",
      "Test features:  (2000, 784)\n",
      "Test labels:    (2000,)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = train[...,1:], train[...,:1].reshape((40000))\n",
    "test_x, test_y = test[...,1:], test[...,:1].reshape((2000))\n",
    "\n",
    "print('Train features:', train_x.shape)\n",
    "print('Train labels:  ', train_y.shape)\n",
    "print('Test features: ', test_x.shape)\n",
    "print('Test labels:   ', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels:   (40000, 10)\n",
      "Test labels:    (2000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_placeholer = np.zeros((train_y.size, train_y.max()+1))\n",
    "train_placeholer[np.arange(train_y.size),train_y] = 1\n",
    "train_y = train_placeholer\n",
    "\n",
    "test_placeholer = np.zeros((test_y.size, test_y.max()+1))\n",
    "test_placeholer[np.arange(test_y.size),test_y] = 1\n",
    "test_y = test_placeholer\n",
    "\n",
    "print('Train labels:  ', train_y.shape)\n",
    "print('Test labels:   ', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (40000, 28, 28, 1)\n",
      "Test features:  (2000, 28, 28, 1)\n",
      "Validate features:  (2000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x = train_x.reshape((40000, 28, 28, 1))\n",
    "test_x = test_x.reshape((2000, 28, 28, 1))\n",
    "validate = validate.reshape((28000, 28, 28, 1))\n",
    "\n",
    "print('Train features:', train_x.shape)\n",
    "print('Test features: ', test_x.shape)\n",
    "print('Validate features: ', test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data done, now Model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# x = Input(shape=(row, col, pixel))\n",
    "\n",
    "model.add(Conv2D(14, (3, 3), input_shape=(28, 28, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(14, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "# Encodes a row of pixels using TimeDistributed Wrapper.\n",
    "# encoded_rows = TimeDistributed(LSTM(row_hidden))(x)\n",
    "model.add(TimeDistributed(LSTM(128, input_shape=(28,28,1))))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 293s 7ms/step - loss: 0.6690 - acc: 0.7673 - val_loss: 0.1931 - val_acc: 0.9440\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 293s 7ms/step - loss: 0.1521 - acc: 0.9537 - val_loss: 0.1575 - val_acc: 0.9525\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 297s 7ms/step - loss: 0.1031 - acc: 0.9680 - val_loss: 0.1036 - val_acc: 0.9675\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 304s 8ms/step - loss: 0.0802 - acc: 0.9759 - val_loss: 0.0843 - val_acc: 0.9710\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 299s 7ms/step - loss: 0.0659 - acc: 0.9794 - val_loss: 0.0934 - val_acc: 0.9715\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 301s 8ms/step - loss: 0.0575 - acc: 0.9826 - val_loss: 0.0664 - val_acc: 0.9805\n",
      "Epoch 7/50\n",
      "12288/40000 [========>.....................] - ETA: 3:21 - loss: 0.0511 - acc: 0.9839"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(test_x, test_y))\n",
    "\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [1 0]\n",
      " [2 9]]\n"
     ]
    }
   ],
   "source": [
    "predictions_raw = model.predict(validate)\n",
    "predictions = np.argmax(predictions_raw, axis=1)\n",
    "indexes = np.arange(predictions.shape[0])\n",
    "# print(indexes[:3])\n",
    "\n",
    "stacked = np.stack((indexes, predictions), axis=1)\n",
    "\n",
    "print(stacked[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"toValidate.csv\", stacked.astype(int), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = ''\n",
    "for i,v in enumerate(stacked):\n",
    "    csv+=','.join([str(i),str(int(v[1]))]) + '\\n'\n",
    "\n",
    "with open('toValidate.csv', 'w') as f:\n",
    "    f.write(csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
