{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, TimeDistributed, Flatten, Dropout, Reshape\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 785) (2000, 785) (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('/root/sharedfolder/train.csv', delimiter=',')\n",
    "train, test = data[:40000, ...].astype(int), data[40000:, ...].astype(int)\n",
    "\n",
    "validate = np.genfromtxt('/root/sharedfolder/test.csv', delimiter=',').astype(int)\n",
    "\n",
    "print(train.shape, test.shape, validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (40000, 784)\n",
      "Train labels:   (40000,)\n",
      "Test features:  (2000, 784)\n",
      "Test labels:    (2000,)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = train[...,1:], train[...,:1].reshape((40000))\n",
    "test_x, test_y = test[...,1:], test[...,:1].reshape((2000))\n",
    "\n",
    "print('Train features:', train_x.shape)\n",
    "print('Train labels:  ', train_y.shape)\n",
    "print('Test features: ', test_x.shape)\n",
    "print('Test labels:   ', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels:   (40000, 10)\n",
      "Test labels:    (2000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_placeholer = np.zeros((train_y.size, train_y.max()+1))\n",
    "train_placeholer[np.arange(train_y.size),train_y] = 1\n",
    "train_y = train_placeholer\n",
    "\n",
    "test_placeholer = np.zeros((test_y.size, test_y.max()+1))\n",
    "test_placeholer[np.arange(test_y.size),test_y] = 1\n",
    "test_y = test_placeholer\n",
    "\n",
    "print('Train labels:  ', train_y.shape)\n",
    "print('Test labels:   ', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (40000, 28, 28, 1)\n",
      "Test features:  (2000, 28, 28, 1)\n",
      "Validate features:  (2000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x = train_x.reshape((40000, 28, 28, 1))\n",
    "test_x = test_x.reshape((2000, 28, 28, 1))\n",
    "validate = validate.reshape((28000, 28, 28, 1))\n",
    "\n",
    "print('Train features:', train_x.shape)\n",
    "print('Test features: ', test_x.shape)\n",
    "print('Validate features: ', test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data done, now Model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 26, 26, 14)        140       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 26, 26, 14)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 13, 13, 14)        0         \n",
      "=================================================================\n",
      "Total params: 140\n",
      "Trainable params: 140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# x = Input(shape=(row, col, pixel))\n",
    "\n",
    "model.add(Conv2D(14, (3, 3), input_shape=(28, 28, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.summary()\n",
    "model.add(Reshape((169, 14)))\n",
    "\n",
    "# model.add(Conv2D(14, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "# Encodes a row of pixels using TimeDistributed Wrapper.\n",
    "# encoded_rows = TimeDistributed(LSTM(row_hidden))(x)\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 163s 4ms/step - loss: 0.7995 - acc: 0.7076 - val_loss: 0.4575 - val_acc: 0.8480\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 162s 4ms/step - loss: 0.3015 - acc: 0.9052 - val_loss: 0.2109 - val_acc: 0.9345\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 161s 4ms/step - loss: 0.1799 - acc: 0.9475 - val_loss: 0.1608 - val_acc: 0.9545\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 162s 4ms/step - loss: 0.1371 - acc: 0.9603 - val_loss: 0.2164 - val_acc: 0.9360\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 174s 4ms/step - loss: 0.1163 - acc: 0.9664 - val_loss: 0.1134 - val_acc: 0.9705\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 191s 5ms/step - loss: 0.1016 - acc: 0.9704 - val_loss: 0.1220 - val_acc: 0.9630\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 175s 4ms/step - loss: 0.0809 - acc: 0.9766 - val_loss: 0.1455 - val_acc: 0.9615\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 189s 5ms/step - loss: 0.0827 - acc: 0.9755 - val_loss: 0.0834 - val_acc: 0.9765\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 164s 4ms/step - loss: 0.0742 - acc: 0.9772 - val_loss: 0.0956 - val_acc: 0.9710\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 164s 4ms/step - loss: 0.0663 - acc: 0.9802 - val_loss: 0.0839 - val_acc: 0.9755\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 162s 4ms/step - loss: 0.0614 - acc: 0.9823 - val_loss: 0.0742 - val_acc: 0.9760\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 162s 4ms/step - loss: 0.0595 - acc: 0.9830 - val_loss: 0.0623 - val_acc: 0.9815\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 162s 4ms/step - loss: 0.0514 - acc: 0.9849 - val_loss: 0.0709 - val_acc: 0.9815\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 162s 4ms/step - loss: 0.0461 - acc: 0.9867 - val_loss: 0.0907 - val_acc: 0.9790\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 163s 4ms/step - loss: 0.0459 - acc: 0.9860 - val_loss: 0.0487 - val_acc: 0.9865\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 164s 4ms/step - loss: 0.0413 - acc: 0.9876 - val_loss: 0.0607 - val_acc: 0.9820\n",
      "Epoch 17/50\n",
      "29824/40000 [=====================>........] - ETA: 41s - loss: 0.0415 - acc: 0.9869"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-6dae4fab1ea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           validation_data=(test_x, test_y))\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# score = model.evaluate(x_test, y_test, verbose=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(test_x, test_y))\n",
    "\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [1 0]\n",
      " [2 9]]\n"
     ]
    }
   ],
   "source": [
    "predictions_raw = model.predict(validate)\n",
    "predictions = np.argmax(predictions_raw, axis=1)\n",
    "indexes = np.arange(predictions.shape[0])\n",
    "# print(indexes[:3])\n",
    "\n",
    "stacked = np.stack((indexes, predictions), axis=1)\n",
    "\n",
    "print(stacked[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"toValidate.csv\", stacked.astype(int), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = ''\n",
    "for i,v in enumerate(stacked):\n",
    "    csv+=','.join([str(i),str(int(v[1]))]) + '\\n'\n",
    "\n",
    "with open('toValidate.csv', 'w') as f:\n",
    "    f.write(csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
